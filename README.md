# ğŸš€ QA Automation Framework

[![Python](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)
[![Pytest](https://img.shields.io/badge/Pytest-8.4.2-green.svg)](https://pytest.org/)
[![Selenium](https://img.shields.io/badge/Selenium-4.x-orange.svg)](https://www.selenium.dev/)

**Comprehensive test automation framework** for **UI Testing (Selenium WebDriver)** and **API Testing (Requests)** using **Pytest**. Built as an assignment solution with emphasis on scalable framework design, data-driven testing using pytest parametrize, and comprehensive validations.

> **Note**: This framework was developed as a take-home assignment demonstrating scalable automation framework design following industry best practices.

## ğŸ¥ Demo

![Test Execution Demo](qa-automation-framework.gif)

*UI test running locally - Complete Twitch search flow (67 seconds)*

> ğŸ“Œ **For Recruiters**: Quick links to key sections:
> - [ğŸ“„ Assignment Overview](#assignment-overview) - What was built and why
> - [ğŸ“‹ Test Cases Documentation](#test-cases-documentation) - Detailed test cases in table format
> - [âœ… Validation Strategy](#validation-strategy) - What validations are used and why
> - [ğŸ“Š Summary](#summary) - Key highlights and test results
> 
> ğŸ“„ **Additional Documents**:
> - **[TEST_CASES_SUMMARY.md](TEST_CASES_SUMMARY.md)** - Quick reference guide (1-page summary)
> - **[ASSIGNMENT_CHECKLIST.md](ASSIGNMENT_CHECKLIST.md)** - Complete requirements verification

## ğŸ“‹ Table of Contents
- [Assignment Overview](#assignment-overview)
- [Features](#features)
- [Technologies](#technologies)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Running Tests](#running-tests)
- [Test Reports](#test-reports)
- [Performance](#performance)
- [Test Coverage](#test-coverage)
- [Test Cases Documentation](#test-cases-documentation)
  - [A. UI Test Cases (Selenium)](#a-ui-test-cases-selenium-webdriver)
  - [B. API Test Cases (Requests)](#b-api-test-cases-requests-library)
- [Validation Strategy](#validation-strategy)
- [Test Examples](#test-examples)
- [Configuration](#configuration)

---

## ğŸ“„ Assignment Overview

### Requirements
This framework was built as a **7-day take-home assignment** for an AQA (Automation Quality Assurance) position with the following requirements:

#### âœ… A. Web App Testing (UI Automation)
- **Objective**: Create a Selenium-based framework with Page Object Model
- **Test Application**: [Twitch.tv](https://www.twitch.tv)
- **Test Scenario**: 
  1. Navigate to Twitch
  2. Click search icon
  3. Input "StarCraft II"
  4. Scroll down 2 times
  5. Select one streamer
  6. Wait for page to load
  7. Take screenshot
- **Requirements**: 
  - Must run in Mobile emulator from Google Chrome
  - Handle modals/popups
  - Scalable framework design
  
#### âœ… B. API Testing (API Automation)
- **Objective**: Create an automated API testing framework
- **API Selection**: [IPStack Geolocation API](https://ipstack.com) (selected from [public-apis repository](https://github.com/public-apis/public-apis))
- **Requirements**:
  - Minimum **4 automated test cases**
  - **Test results validation** (status codes, response data, performance)
  - **Use pytest parametrize** for data-driven testing
  - **Include test cases in table form** in README
  - **Provide validation descriptions** (what and why)

### ğŸ¯ What Was Delivered

| Requirement | Status | Details |
|-------------|--------|---------|
| UI Automation (Selenium) | âœ… **Complete** | 5 test cases covering search, navigation, scroll, mobile responsiveness |
| API Automation (Requests) | âœ… **Complete** | 8+ test cases with parametrization, negative testing, performance validation |
| Page Object Model | âœ… **Implemented** | Clean separation: `BasePage`, `TwitchHomePage`, `TwitchStreamerPage` |
| Mobile Emulation | âœ… **Implemented** | Chrome mobile emulation (360x640 viewport) |
| Pytest Parametrize | âœ… **Used extensively** | Multiple IPs, geographic regions, negative tests |
| Test Cases Table | âœ… **Documented** | Comprehensive tables with Test ID, Steps, Validations, Expected Results |
| Validation Descriptions | âœ… **Documented** | 10 validation strategies with "What" and "Why" explanations |
| Scalable Framework | âœ… **Designed** | Modular structure, reusable fixtures, configurable via YAML |
| Test Reports | âœ… **Multiple formats** | HTML Report, Allure Report, Screenshots, Logs |
| Performance Optimization | âœ… **52% faster** | Reduced execution time from 140s â†’ 67s |
| CI/CD Ready | âœ… **GitHub Actions** | Automated test execution on push/PR |
| Documentation | âœ… **Comprehensive** | README, Architecture docs, Quick Start guides |

---

## âœ¨ Features

- âœ… **UI Automation** - Selenium WebDriver with Page Object Model
- âœ… **API Automation** - RESTful API testing with Requests
- âœ… **Pytest Framework** - Industry-standard test runner
- âœ… **Allure Reports** - Beautiful test reports with screenshots
- âœ… **Parallel Execution** - Fast test execution
- âœ… **CI/CD Ready** - GitHub Actions compatible
- âœ… **Optimized Performance** - 52% faster execution (140s â†’ 67s)
- âœ… **Page Object Model** - Maintainable UI test architecture
- âœ… **Data-Driven Testing** - Parameterized tests
- âœ… **Comprehensive Logging** - Detailed test execution logs

## ğŸ› ï¸ Technologies

| Category | Technology |
|----------|-----------|
| Language | Python 3.13 |
| Test Framework | Pytest 8.4.2 |
| UI Automation | Selenium WebDriver 4.x |
| API Testing | Requests 2.32.3 |
| Reports | Allure, HTML |
| Assertions | Pytest assertions |
| Data Validation | Pydantic |
| Browser Management | WebDriver Manager |

## ğŸ“ Project Structure

```
qa-automation-framework/
â”‚
â”œâ”€â”€ api_tests/                      # API Testing Suite
â”‚   â”œâ”€â”€ api_clients/                # API client implementations
â”‚   â”‚   â”œâ”€â”€ base_client.py          # Base HTTP client
â”‚   â”‚   â”œâ”€â”€ ipstack_client.py       # IPStack API client
â”‚   â”‚   â””â”€â”€ objects_client.py       # Objects API client
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.yml              # API configuration
â”‚   â”œâ”€â”€ models/                     # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ ipstack_model.py
â”‚   â”‚   â””â”€â”€ object_model.py
â”‚   â”œâ”€â”€ tests/                      # API test cases
â”‚   â”‚   â”œâ”€â”€ test_ipstack_geolocation.py
â”‚   â”‚   â””â”€â”€ test_objects_crud.py
â”‚   â”œâ”€â”€ utils/                      # Helper utilities
â”‚   â”‚   â”œâ”€â”€ api_helper.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ conftest.py                 # Pytest fixtures
â”‚   â””â”€â”€ pytest.ini                  # Pytest configuration
â”‚
â”œâ”€â”€ ui_tests/                       # UI Testing Suite
â”‚   â”œâ”€â”€ pages/                      # Page Object Model
â”‚   â”‚   â”œâ”€â”€ base_page.py            # Base page class
â”‚   â”‚   â”œâ”€â”€ twitch_home_page.py     # Twitch homepage
â”‚   â”‚   â””â”€â”€ twitch_streamer_page.py # Streamer page
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.yml              # UI configuration
â”‚   â”œâ”€â”€ tests/                      # UI test cases
â”‚   â”‚   â””â”€â”€ test_twitch_search.py   # Twitch search tests
â”‚   â”œâ”€â”€ utils/                      # Helper utilities
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ screenshot_helper.py
â”‚   â”œâ”€â”€ conftest.py                 # Pytest fixtures
â”‚   â””â”€â”€ pytest.ini                  # Pytest configuration
â”‚
â”œâ”€â”€ shared/                         # Shared utilities
â”‚   â”œâ”€â”€ config/
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ common_logger.py
â”‚       â””â”€â”€ data_generator.py
â”‚
â”œâ”€â”€ reports/                        # Test reports
â”‚   â””â”€â”€ screenshots/                # Test screenshots
â”‚
â”œâ”€â”€ logs/                           # Execution logs
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ pytest.ini                      # Root pytest config
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Installation

### Prerequisites
- Python 3.13+
- Chrome browser (for UI tests)
- pip (Python package manager)

### Setup

1. **Clone the repository:**
```bash
git clone https://github.com/YOUR_USERNAME/qa-automation-framework.git
cd qa-automation-framework
```

2. **Create virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

## ğŸ§ª Running Tests

### âš¡ Quick Start (One Command)

The easiest way to run tests:

```bash
# Using Makefile (recommended)
make test              # Run all tests
make test-demo         # Run demo (shown in GIF)
make test-api          # Run API tests only
make test-ui           # Run UI tests only
make help              # Show all commands

# OR using shell script
./run_tests.sh         # Interactive menu
./run_tests.sh all     # Run all tests
./run_tests.sh demo    # Run demo

# OR traditional Pytest
pytest                 # Run all tests
```

### ğŸ“ All Available Commands

#### Using Makefile (Like TestNG.xml)
```bash
make install           # Install dependencies
make test              # Run all tests (API + UI)
make test-api          # Run API tests only
make test-ui           # Run UI tests only
make test-smoke        # Run smoke tests only
make test-demo         # Run quick demo (for GIF)
make test-html         # Run with HTML report
make test-allure       # Run with Allure report
make clean             # Clean up generated files
```

#### Using Shell Script
```bash
./run_tests.sh all     # Run all tests
./run_tests.sh api     # Run API tests
./run_tests.sh ui      # Run UI tests
./run_tests.sh demo    # Run demo
./run_tests.sh html    # Generate HTML report
```

#### Traditional Pytest Commands
```bash
# Run all tests
pytest -v

# Run specific test suite
pytest api_tests/ -v
pytest ui_tests/ -v --browser=chrome

# Run specific test
pytest ui_tests/tests/test_twitch_search.py::TestTwitchSearch::test_search_starcraft_and_select_streamer -v

# Run by markers
pytest -m smoke -v
pytest -m api -v
pytest -m ui -v

# Run with reports
pytest --html=reports/test-report.html --self-contained-html
pytest --alluredir=reports/allure-results

# Run in parallel
pytest -n auto
```

## ğŸ“Š Test Reports

After test execution, reports are generated in multiple formats:

- **HTML Report:** `reports/test-report.html`
- **Allure Report:** `reports/allure-results/`
- **Screenshots:** `reports/screenshots/`
- **Logs:** `logs/pytest.log`

## âš¡ Performance

### Optimization Results:

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| UI Test Execution | 140s | 67s | **52% faster** |
| Implicit Wait | 10s | 1s | **90% reduction** |
| Page Load Timeout | 30s | 8s | **73% reduction** |

### Key Optimizations:
- âœ… Aggressive timeout reduction
- âœ… 'eager' page load strategy
- âœ… Disabled image loading
- âœ… Optimized explicit waits
- âœ… Reduced sleep times
- âœ… Parallel execution support

## ğŸ¯ Test Coverage

### UI Tests (Selenium)
- âœ… Search functionality
- âœ… Navigation flows
- âœ… Element interactions
- âœ… Screenshot capture
- âœ… Modal handling
- âœ… Dynamic content loading

### API Tests (Requests)
- âœ… CRUD operations
- âœ… Response validation
- âœ… Status code checks
- âœ… Performance testing
- âœ… Error handling
- âœ… Data model validation

---

## ğŸ“‹ Test Cases Documentation

### ğŸŒ A. UI Test Cases (Selenium WebDriver)

**Test Application**: [Twitch.tv](https://www.twitch.tv)  
**Browser**: Chrome (with Mobile Emulation support)  
**Framework**: Selenium WebDriver 4.x + Pytest + Page Object Model

| Test ID | Test Case | Steps | Expected Result | Status | Priority |
|---------|-----------|-------|----------------|--------|----------|
| **UI-001** | **Search for StarCraft II and select LIVE streamer** | 1. Navigate to https://www.twitch.tv<br>2. Click the search icon<br>3. Input "StarCraft II" in search<br>4. Press ENTER to submit search<br>5. Wait for Search Results Page to load<br>6. Verify "Channels" tab with live streamers<br>7. Scroll down 2 times<br>8. Click first LIVE streamer<br>9. Wait for streamer page to load<br>10. Handle popups (mature content, cookies)<br>11. Take screenshot | âœ“ Homepage loads successfully<br>âœ“ Search icon is clickable<br>âœ“ Search results page displays<br>âœ“ Live streamers are visible<br>âœ“ Scroll loads more content<br>âœ“ Navigation to streamer page<br>âœ“ Page loads with video player<br>âœ“ Screenshot saved | âœ… PASS | CRITICAL |
| **UI-002** | **Search functionality verification** | 1. Navigate to Twitch<br>2. Click search icon<br>3. Verify search input appears | âœ“ Search input field is visible and functional | âœ… PASS | SMOKE |
| **UI-003** | **Search results display verification** | 1. Navigate to Twitch<br>2. Perform search for "StarCraft II"<br>3. Verify results are displayed<br>4. Count streamer cards | âœ“ Search results page loads<br>âœ“ At least 1 streamer card is visible | âœ… PASS | REGRESSION |
| **UI-004** | **Scroll functionality verification** | 1. Navigate and search<br>2. Get initial card count<br>3. Scroll down 2 times<br>4. Get final card count | âœ“ Card count remains same or increases<br>âœ“ No content is lost during scroll | âœ… PASS | UI |
| **UI-008** | **Mobile responsive search flow** | 1. Open Twitch in mobile emulation (360x640)<br>2. Perform search<br>3. Verify mobile layout<br>4. Take screenshot | âœ“ Search works in mobile viewport<br>âœ“ Layout adapts to mobile screen | âœ… PASS | MOBILE |

**Test Execution Details:**
- **Total UI Tests**: 5 test cases
- **Execution Time**: ~67 seconds (optimized from 140s)
- **Test Markers**: `@pytest.mark.ui`, `@pytest.mark.smoke`, `@pytest.mark.regression`, `@pytest.mark.mobile`
- **Reports**: HTML Report + Allure Report + Screenshots

---

### ğŸ”Œ B. API Test Cases (Requests Library)

**API Selection**: [IPStack Geolocation API](https://ipstack.com)  
**Base URL**: `https://api.ipstack.com`  
**Method**: REST API (GET requests)  
**Framework**: Requests + Pytest + Pydantic Models

| Test ID | Test Case | Request Details | Validations | Expected Result | Status | Priority |
|---------|-----------|----------------|-------------|-----------------|--------|----------|
| **IPSTACK-001** | **Lookup specific IP - Basic validation** | **Method**: GET<br>**Endpoint**: `/134.201.250.155`<br>**IP**: 134.201.250.155 | 1. Status code = 200<br>2. Response time < 10s<br>3. Required fields present (ip, type, country_code, country_name, latitude, longitude)<br>4. IP matches request<br>5. IP type is 'ipv4' or 'ipv6'<br>6. Latitude: -90 to 90<br>7. Longitude: -180 to 180<br>8. Pydantic model validation | âœ“ Response returns valid geolocation data<br>âœ“ All required fields present<br>âœ“ Data types are correct<br>âœ“ Coordinates within valid range | âœ… PASS | CRITICAL |
| **IPSTACK-002** | **Geographic data validation** | **Method**: GET<br>**Endpoint**: `/134.201.250.155`<br>**IP**: 134.201.250.155 | 1. Country code (2 char ISO)<br>2. Country name non-empty<br>3. Region/State info present<br>4. City information available<br>5. Location object populated<br>6. Continent name valid<br>7. ZIP code format (US: numeric)<br>8. Calling code present | âœ“ Comprehensive geographic data returned<br>âœ“ Country: United States (US)<br>âœ“ Location details accurate<br>âœ“ Data completeness verified | âœ… PASS | CRITICAL |
| **IPSTACK-003** | **API performance validation** | **Method**: GET<br>**Endpoint**: `/134.201.250.155`<br>**IP**: 134.201.250.155 | 1. Response time < 10s<br>2. Performance metrics logged<br>3. Status code = 200 | âœ“ API responds within acceptable time<br>âœ“ Performance meets SLA | âœ… PASS | PERFORMANCE |
| **IPSTACK-004** | **Connection type and routing validation** | **Method**: GET<br>**Endpoint**: `/134.201.250.155`<br>**IP**: 134.201.250.155 | 1. IP routing type present<br>2. Connection type present<br>3. Optional fields populated<br>4. Technical details available | âœ“ Network routing information returned<br>âœ“ Connection type identified | âœ… PASS | REGRESSION |
| **IPSTACK-005** | **Multiple IP addresses - Parametrized** | **Method**: GET<br>**Endpoints**: <br>- `/134.201.250.155` (US)<br>- `/8.8.8.8` (Google DNS) | **Uses `@pytest.mark.parametrize`**<br>1. Status code = 200<br>2. IP matches request<br>3. Country code matches expected<br>4. Required fields present<br>5. Coordinates present | âœ“ Data-driven testing successful<br>âœ“ Multiple IPs validated<br>âœ“ Country codes verified | âœ… PASS | SMOKE |
| **IPSTACK-006** | **Geographic regions validation - Parametrized** | **Method**: GET<br>**Endpoints**:<br>- `/134.201.250.155`<br>- `/8.8.8.8` | **Uses `@pytest.mark.parametrize`**<br>1. Continent name matches expected<br>2. Geographic classification accurate<br>3. Region data present | âœ“ Continent: North America<br>âœ“ Geographic data accurate | âœ… PASS | REGRESSION |
| **IPSTACK-007** | **Invalid IP handling - Negative test** | **Method**: GET<br>**Endpoint**: `/999.999.999.999`<br>**IP**: Invalid IP | **Uses `@pytest.mark.parametrize`**<br>1. Error response returned<br>2. 'success' field = false<br>3. Error message present<br>4. Graceful error handling | âœ“ API handles invalid input gracefully<br>âœ“ Proper error response | âœ… PASS | NEGATIVE |
| **IPSTACK-008** | **Response data types validation** | **Method**: GET<br>**Endpoint**: `/134.201.250.155`<br>**IP**: 134.201.250.155 | 1. String fields type check<br>2. Numeric fields type check<br>3. Boolean fields type check<br>4. Array fields type check<br>5. Nested object validation<br>6. Pydantic comprehensive validation | âœ“ All data types correct<br>âœ“ Type safety verified<br>âœ“ Schema validation passed | âœ… PASS | INTEGRATION |

**Test Execution Details:**
- **Total API Tests**: 8+ test cases (including parameterized variations)
- **Execution Time**: ~5-10 seconds
- **Test Markers**: `@pytest.mark.api`, `@pytest.mark.smoke`, `@pytest.mark.regression`, `@pytest.mark.performance`, `@pytest.mark.negative`
- **Parameterization**: Uses `@pytest.mark.parametrize` for data-driven testing
- **Reports**: HTML Report + Allure Report

---

## âœ… Validation Strategy

### What Validations Are Used and Why

#### 1ï¸âƒ£ **HTTP Status Code Validation**
**What**: Verify response status codes (200, 404, etc.)  
**Why**: Ensures API returns correct HTTP status for successful and failed requests. Status codes are the first indicator of API health.

```python
assert response.status_code == 200, f"Expected 200, got {response.status_code}"
```

#### 2ï¸âƒ£ **Response Time / Performance Validation**
**What**: Measure and validate API response time is under acceptable threshold (< 10 seconds)  
**Why**: Performance is critical for user experience. Slow APIs lead to timeout issues in production.

```python
response_time = response.elapsed.total_seconds()
assert validate_response_time(response_time, 10.0)
```

#### 3ï¸âƒ£ **Schema Validation (Required Fields)**
**What**: Verify response contains all required fields (ip, country_code, latitude, longitude, etc.)  
**Why**: Ensures API contract is maintained. Missing fields can break client applications.

```python
required_fields = ['ip', 'type', 'country_code', 'country_name', 'latitude', 'longitude']
for field in required_fields:
    assert field in response_json
```

#### 4ï¸âƒ£ **Data Type Validation (Pydantic Models)**
**What**: Validate data types using Pydantic models (string, int, float, bool, list, dict)  
**Why**: Type safety prevents runtime errors. Pydantic provides automatic validation and clear error messages.

```python
# Pydantic automatically validates types
geolocation = IpstackResponse(**response_json)
```

#### 5ï¸âƒ£ **Business Logic Validation**
**What**: Validate business rules (e.g., latitude between -90 to 90, longitude between -180 to 180, country code is 2 characters)  
**Why**: Ensures data makes sense in real-world context. Invalid coordinates would break map integrations.

```python
assert -90 <= latitude <= 90, f"Latitude {latitude} must be between -90 and 90"
assert -180 <= longitude <= 180, f"Longitude {longitude} must be between -180 and 180"
```

#### 6ï¸âƒ£ **Data Completeness Validation**
**What**: Verify optional fields are populated when expected (city, region, timezone, location object)  
**Why**: Ensures API provides comprehensive data. Incomplete data reduces API value.

```python
assert len(response_json['country_name']) > 0, "Country name should not be empty"
```

#### 7ï¸âƒ£ **Data Consistency Validation**
**What**: Verify returned IP matches requested IP, continent matches country, etc.  
**Why**: Ensures API returns correct data for the request. Inconsistent data indicates API bugs.

```python
assert response_json['ip'] == test_ip, "Response IP should match requested IP"
```

#### 8ï¸âƒ£ **Negative Testing / Error Handling**
**What**: Test with invalid inputs (999.999.999.999) and verify proper error responses  
**Why**: Ensures API handles bad input gracefully. Production systems must handle errors without crashing.

```python
assert response_json['success'] == False, "Should return error for invalid IP"
```

#### 9ï¸âƒ£ **Parametrized Testing (Data-Driven)**
**What**: Use `@pytest.mark.parametrize` to test multiple IPs with different expected values  
**Why**: Reduces code duplication, increases test coverage with minimal code, makes tests maintainable.

```python
@pytest.mark.parametrize("ip_address,expected_country", [
    ("134.201.250.155", "US"),
    ("8.8.8.8", "US"),
])
def test_lookup_multiple_ips(self, ipstack_client, ip_address, expected_country):
    # Test logic
```

#### ğŸ”Ÿ **UI Validation (Selenium)**
**What**: 
- Element presence validation (`is_element_visible`)
- Navigation validation (URL changes)
- Content loading validation (scroll increases cards)
- Screenshot capture for visual verification

**Why**: 
- **Element Presence**: Ensures page loaded correctly and elements are interactive
- **Navigation**: Verifies user flows work end-to-end
- **Content Loading**: Dynamic content (infinite scroll) loads properly
- **Screenshots**: Provides visual evidence for test results and debugging

```python
assert home_page.is_search_results_displayed(), "Search results should be displayed"
assert len(cards) > 0, "At least one search result should be displayed"
screenshot_path = streamer_page.take_page_screenshot("streamer_page_final")
```

---

## ğŸ“ Test Examples

### UI Test Example
```python
def test_search_starcraft_and_select_streamer(self, driver):
    home_page = TwitchHomePage(driver)
    home_page.open()
    home_page.search_for("StarCraft II")
    home_page.scroll_down(times=2)
    home_page.click_first_streamer()
    
    streamer_page = TwitchStreamerPage(driver)
    streamer_page.wait_for_page_to_load()
    assert streamer_page.is_page_loaded_successfully()
```

### API Test Example
```python
def test_lookup_specific_ip(self, ipstack_client):
    response = ipstack_client.lookup_ip("134.201.250.155")
    assert response.status_code == 200
    assert response.json()['country_code'] == 'US'
```

## ğŸ”§ Configuration

### API Configuration (`api_tests/config/config.yml`)
```yaml
api:
  base_url: "https://api.restful-api.dev"
  timeout: 30

ipstack:
  base_url: "https://api.ipstack.com"
  access_key: "YOUR_KEY"
```

### UI Configuration (`ui_tests/config/config.yml`)
```yaml
urls:
  twitch: "https://www.twitch.tv"

browser:
  default: chrome
  headless: false

timeouts:
  implicit_wait: 1
  page_load: 8
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ‘¤ Author

Vinay Rathod

## ğŸ“§ Contact

For questions or feedback, please reach out via email or GitHub issues.

---

## ğŸ“Š Summary

### Key Highlights for Recruiters

âœ… **Complete Assignment Compliance**
- All requirements met and exceeded
- 5 UI tests + 8+ API tests (minimum 4 required)
- Pytest parametrize used extensively
- Test cases documented in table format
- Validation strategies explained with "what" and "why"

âœ… **Production-Ready Quality**
- Clean, maintainable code following PEP 8
- Page Object Model architecture
- Comprehensive error handling
- Detailed logging and reporting
- Performance optimized (52% faster)

âœ… **Scalable Framework Design**
- Modular structure (`api_tests/`, `ui_tests/`, `shared/`)
- Configuration-driven (YAML files)
- Reusable fixtures and helpers
- Easy to extend with new tests
- CI/CD ready with GitHub Actions

âœ… **Professional Documentation**
- Clear README with examples
- Architecture documentation
- Setup guides and troubleshooting
- Test case documentation
- Inline code comments

### Test Results
- âœ… **UI Tests**: 5/5 passing (67 seconds)
- âœ… **API Tests**: 8+/8+ passing (5-10 seconds)
- âœ… **Total Coverage**: 100% of required test scenarios
- âœ… **Reports**: HTML, Allure, Screenshots, Logs

---

**Happy Testing! ğŸš€**
